{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbxvIv0S75GT"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import time\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "from skimage import measure\n",
        "from collections import deque\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.segmentation import find_boundaries\n",
        "\n",
        "\n",
        "# Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Part 1 Definition of SLIC class"
      ],
      "metadata": {
        "id": "gD_lNykM_6Rq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SLIC:\n",
        "    def __init__(self, img, step, m):\n",
        "        self.img = img\n",
        "        self.height, self.width = img.shape[:2]\n",
        "        self._convertToLAB()\n",
        "        self.step = step\n",
        "        self.m = m\n",
        "        self.ws = step\n",
        "        self.FLT_MAX = 1000000\n",
        "        self.ITERATIONS = 10\n",
        "\n",
        "    def _convertToLAB(self):\n",
        "        try:\n",
        "            import cv2\n",
        "            self.labimg = cv2.cvtColor(self.img, cv2.COLOR_BGR2LAB).astype(np.float64)\n",
        "        except ImportError as e:\n",
        "            print(f\"OpenCV import failed: {e}, using custom RGB to LAB conversion.\")\n",
        "            self.labimg = np.copy(self.img)\n",
        "\n",
        "            for i in range(self.labimg.shape[0]):\n",
        "                for j in range(self.labimg.shape[1])\n",
        "                    rgb_reversed = tuple(reversed(self.labimg[i, j]))\n",
        "                    self.labimg[i, j] = self._rgb2lab(rgb_reversed)\n",
        "\n",
        "    def _rgb2lab(self, inputColor):\n",
        "        ref_X, ref_Y, ref_Z = 95.047, 100.000, 108.883\n",
        "        RGB = [float(value) / 255 for value in inputColor]\n",
        "        RGB = [( (value + 0.055) / 1.055 ) ** 2.4 if value > 0.04045 else value / 12.92 for value in RGB]\n",
        "        RGB = [value * 100 for value in RGB]\n",
        "\n",
        "        X = round(RGB[0] * 0.4124 + RGB[1] * 0.3576 + RGB[2] * 0.1805, 4)\n",
        "        Y = round(RGB[0] * 0.2126 + RGB[1] * 0.7152 + RGB[2] * 0.0722, 4)\n",
        "        Z = round(RGB[0] * 0.0193 + RGB[1] * 0.1192 + RGB[2] * 0.9505, 4)\n",
        "\n",
        "        XYZ = [X / ref_X, Y / ref_Y, Z / ref_Z]\n",
        "        XYZ = [value ** (1/3) if value > 0.008856 else (7.787 * value) + (16 / 116) for value in XYZ]\n",
        "\n",
        "        L = round((116 * XYZ[1]) - 16, 4)\n",
        "        a = round(500 * (XYZ[0] - XYZ[1]), 4)\n",
        "        b = round(200 * (XYZ[1] - XYZ[2]), 4)\n",
        "\n",
        "        return [L, a, b]\n",
        "\n",
        "    def generateSuperPixels(self):\n",
        "        self._initData()\n",
        "        indnp = np.mgrid[0:self.height, 0:self.width].swapaxes(0, 2).swapaxes(0, 1)\n",
        "\n",
        "        for i in range(self.ITERATIONS):\n",
        "            self.distances = self.FLT_MAX * np.ones(self.img.shape[:2])\n",
        "\n",
        "            for j in range(self.centers.shape[0]):\n",
        "                xlow = max(int(self.centers[j][3] - self.step), 0)\n",
        "                xhigh = min(int(self.centers[j][3] + self.step), self.width)\n",
        "                ylow = max(int(self.centers[j][4] - self.step), 0)\n",
        "                yhigh = min(int(self.centers[j][4] + self.step), self.height)\n",
        "\n",
        "                cropimg = self.labimg[ylow:yhigh, xlow:xhigh]\n",
        "                colordiff = cropimg - self.labimg[int(self.centers[j][4]), int(self.centers[j][3])]\n",
        "                colorDist = np.sqrt(np.sum(np.square(colordiff), axis=2))\n",
        "                yy, xx = np.ogrid[ylow:yhigh, xlow:xhigh]\n",
        "                pixdist = np.sqrt((yy - self.centers[j][4])**2 + (xx - self.centers[j][3])**2)\n",
        "                dist = np.sqrt((colorDist / self.m)**2 + (pixdist / self.ws)**2)\n",
        "\n",
        "                distanceCrop = self.distances[ylow:yhigh, xlow:xhigh]\n",
        "                idx = dist < distanceCrop\n",
        "                distanceCrop[idx] = dist[idx]\n",
        "                self.distances[ylow:yhigh, xlow:xhigh] = distanceCrop\n",
        "                self.clusters[ylow:yhigh, xlow:xhigh][idx] = j\n",
        "\n",
        "            for k in range(len(self.centers)):\n",
        "                idx = (self.clusters == k)\n",
        "                colornp = self.labimg[idx]\n",
        "                distnp = indnp[idx]\n",
        "                self.centers[k][:3] = np.sum(colornp, axis=0)\n",
        "                sumy, sumx = np.sum(distnp, axis=0)\n",
        "                self.centers[k][3:] = sumx, sumy\n",
        "                self.centers[k] /= np.sum(idx)\n",
        "\n",
        "            print(f'Iteration={i+1}')\n",
        "\n",
        "        print(\"done\")\n",
        "\n",
        "\n",
        "    def _initData(self):\n",
        "        self.clusters = -1 * np.ones(self.img.shape[:2])\n",
        "        self.distances = self.FLT_MAX * np.ones(self.img.shape[:2])\n",
        "        centers = [[*self.labimg[self._findLocalMinimum(center=(i, j))[1], self._findLocalMinimum(center=(i, j))[0]], i, j]\n",
        "                  for j in range(self.step, self.height - self.step//2, self.step)\n",
        "                  for i in range(self.step, self.width - self.step//2, self.step)]\n",
        "        self.centers = np.array(centers)\n",
        "        self.center_counts = np.zeros(len(centers))\n",
        "\n",
        "\n",
        "    def createConnectivity(self):\n",
        "        dx4 = [-1, 0, 1, 0]\n",
        "        dy4 = [0, -1, 0, 1]\n",
        "        lims = int(self.width * self.height / self.centers.shape[0])\n",
        "        new_clusters = -1 * np.ones(self.img.shape[:2]).astype(np.int64)\n",
        "\n",
        "        label = 0\n",
        "        for i in range(self.width):\n",
        "            for j in range(self.height):\n",
        "                if new_clusters[j, i] != -1:\n",
        "                    continue\n",
        "                elements = deque([(j, i)])\n",
        "                adjlabel = -1\n",
        "                count = 1\n",
        "                new_clusters[j, i] = label\n",
        "                while elements:\n",
        "                    y, x = elements.popleft()\n",
        "                    for dx, dy in zip(dx4, dy4):\n",
        "                        nx, ny = x + dx, y + dy\n",
        "                        if 0 <= nx < self.width and 0 <= ny < self.height:\n",
        "                            if new_clusters[ny, nx] == -1 and self.clusters[j, i] == self.clusters[ny, nx]:\n",
        "                                elements.append((ny, nx))\n",
        "                                new_clusters[ny, nx] = label\n",
        "                                count += 1\n",
        "                            elif new_clusters[ny, nx] >= 0:\n",
        "                                adjlabel = new_clusters[ny, nx]\n",
        "                if count <= lims >> 2 and adjlabel != -1:\n",
        "                    new_clusters[new_clusters == label] = adjlabel\n",
        "                    label -= 1\n",
        "\n",
        "                label += 1\n",
        "\n",
        "    def displayContours(self, color):\n",
        "        dx8 = [-1, -1, 0, 1, 1, 1, 0, -1]\n",
        "        dy8 = [0, -1, -1, -1, 0, 1, 1, 1]\n",
        "\n",
        "        isTaken = np.zeros(self.img.shape[:2], np.bool_)\n",
        "\n",
        "        for i in range(self.width):\n",
        "            for j in range(self.height):\n",
        "                nr_p = sum(\n",
        "                    0 <= i + dx < self.width and 0 <= j + dy < self.height and\n",
        "                    not isTaken[j + dy, i + dx] and self.clusters[j, i] != self.clusters[j + dy, i + dx]\n",
        "                    for dx, dy in zip(dx8, dy8)\n",
        "                )\n",
        "\n",
        "                if nr_p >= 2:\n",
        "                    isTaken[j, i] = True\n",
        "\n",
        "        self.img[isTaken] = color\n",
        "\n",
        "\n",
        "    def _findLocalMinimum(self, center):\n",
        "        min_grad = self.FLT_MAX\n",
        "        loc_min = center\n",
        "\n",
        "        for i in range(center[0] - 1, center[0] + 2):\n",
        "            for j in range(center[1] - 1, center[1] + 2):\n",
        "                if i + 1 < self.width and j + 1 < self.height:\n",
        "                    c1 = self.labimg[j + 1, i][0]\n",
        "                    c2 = self.labimg[j, i + 1][0]\n",
        "                    c3 = self.labimg[j, i][0]\n",
        "                    grad = abs(c1 - c3) + abs(c2 - c3)\n",
        "                    if grad < min_grad:\n",
        "                        min_grad = grad\n",
        "                        loc_min = [i, j]\n",
        "\n",
        "        return loc_min\n",
        "\n",
        "\n",
        "    def get_segmentation(self):\n",
        "        return self.clusters.copy()\n"
      ],
      "metadata": {
        "id": "Ir-jJeiy8Egh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2 Generation of **single** superpixel segmentation image"
      ],
      "metadata": {
        "id": "a_lyTeEuAEz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "    img_path = 'Path to your image in Google drive'\n",
        "    img = cv2.imread(img_path)\n",
        "    nr_superpixels = 1000\n",
        "    m = 40\n",
        "    step = int((img.shape[0]*img.shape[1]/nr_superpixels)**0.5)\n",
        "\n",
        "    slic = SLIC(img, step, m)\n",
        "    start_time = time.time()\n",
        "    slic.generateSuperPixels()\n",
        "    slic.createConnectivity()\n",
        "    slic.displayContours([255, 255, 255])\n",
        "    end_time = time.time()\n",
        "\n",
        "\n",
        "    from matplotlib import pyplot as plt\n",
        "    plt.imshow(cv2.cvtColor(slic.img, cv2.COLOR_BGR2RGB))\n",
        "    plt.show()\n",
        "\n",
        "    output_path = 'The path to your image segmentation results in Google drive'\n",
        "    cv2.imwrite(output_path, slic.img)\n",
        "    print(\"Processing time: {:.2f} seconds\".format(end_time - start_time))\n"
      ],
      "metadata": {
        "id": "l5cGnFPj9cJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3 **Batch** generation of superpixel segmentation images and segmentation markers"
      ],
      "metadata": {
        "id": "E7SFFN2bBGDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_subfolders(base_folder):\n",
        "    image_folder = os.path.join(base_folder, \"images\")\n",
        "    segmentation_folder = os.path.join(base_folder, \"segmentations\")\n",
        "\n",
        "    if not os.path.exists(image_folder):\n",
        "        os.makedirs(image_folder)\n",
        "\n",
        "    if not os.path.exists(segmentation_folder):\n",
        "        os.makedirs(segmentation_folder)\n",
        "\n",
        "    return image_folder, segmentation_folder\n",
        "def process_folder(folder_path, output_folder, nr_superpixels, m):\n",
        "    image_folder, segmentation_folder = create_subfolders(output_folder)\n",
        "    segmentation_results = {}\n",
        "    processed_images = []\n",
        "    file_names = []\n",
        "\n",
        "    for i, file_name in enumerate(sorted(os.listdir(folder_path))):\n",
        "        if file_name.endswith('.jpg'):\n",
        "            img_path = os.path.join(folder_path, file_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            step = int((img.shape[0]*img.shape[1]/nr_superpixels)**0.5)\n",
        "\n",
        "            slic = SLIC(img, step, m)\n",
        "            slic.generateSuperPixels()\n",
        "            slic.createConnectivity()\n",
        "            slic.displayContours([255, 255, 255])\n",
        "\n",
        "            segmentation = slic.get_segmentation()\n",
        "            segmentation_results[file_name] = segmentation\n",
        "\n",
        "            output_image_path = os.path.join(image_folder, f\"SLIC_{file_name}\")\n",
        "            cv2.imwrite(output_image_path, slic.img)\n",
        "\n",
        "            segmentation_path = os.path.join(segmentation_folder, f\"SLIC_segmentation_{file_name}.npy\")\n",
        "            np.save(segmentation_path, segmentation)\n",
        "\n",
        "            if i < 5:\n",
        "                processed_images.append(slic.img)\n",
        "                file_names.append(file_name)\n",
        "\n",
        "            print(f\"Processed and saved: {file_name}\")\n",
        "\n",
        "    return processed_images, file_names, segmentation_results\n",
        "\n",
        "def main():\n",
        "    input_folder = 'Path to the image dataset to be segmented in Google drive'\n",
        "    output_folder = 'Storage path in Google drive for superpixel segmentation result images and segmentation markers'\n",
        "    nr_superpixels = 1000\n",
        "    m = 40\n",
        "\n",
        "    processed_images, file_names, segmentations = process_folder(input_folder, output_folder, nr_superpixels, m)\n",
        "\n",
        "    for img, name in zip(processed_images, file_names):\n",
        "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(name)\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "C7mpb2T49oxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4 Processing of the dataset to be used"
      ],
      "metadata": {
        "id": "xkBIJYJbDHYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import scipy.io\n",
        "\n",
        "def extract_segmentation_labels_from_mat(file_path):\n",
        "    data = scipy.io.loadmat(file_path)\n",
        "    ground_truth = data.get('groundTruth')\n",
        "    if ground_truth is None:\n",
        "        raise ValueError(\"Segmentation data not found in the .mat file\")\n",
        "\n",
        "    all_segmentations = []\n",
        "    for i in range(ground_truth.shape[1]):\n",
        "        segmentation = ground_truth[0, i][0, 0][0]\n",
        "        all_segmentations.append(segmentation)\n",
        "\n",
        "    return all_segmentations\n",
        "\n",
        "def process_mat_files(image_folder, mat_folder):\n",
        "    segmentations = {}\n",
        "\n",
        "    for file_name in sorted(os.listdir(image_folder)):\n",
        "        if file_name.endswith('.jpg'):\n",
        "            mat_file_path = os.path.join(mat_folder, file_name.replace('.jpg', '.mat'))\n",
        "            if os.path.exists(mat_file_path):\n",
        "                segmentation_labels = extract_segmentation_labels_from_mat(mat_file_path)\n",
        "                segmentations[file_name] = segmentation_labels\n",
        "            else:\n",
        "                print(f\"Warning: No corresponding .mat file found for {file_name}\")\n",
        "\n",
        "    return segmentations\n",
        "\n",
        "# Path to the folder where the images and .mat files are stored\n",
        "image_folder = 'Path to the folder where the images files are stored'\n",
        "mat_folder = 'Path to the folder where the .mat files are stored'\n",
        "\n",
        "all_segmentations = process_mat_files(image_folder, mat_folder)"
      ],
      "metadata": {
        "id": "zTaWmkACDBYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5 Quantitative Evaluation"
      ],
      "metadata": {
        "id": "Z5aOxKCPEUrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def boundary_recall(slic_segmentation, ground_truth):\n",
        "    slic_segmentation = slic_segmentation.astype(int)\n",
        "    ground_truth = ground_truth.astype(int)\n",
        "\n",
        "    slic_boundaries = find_boundaries(slic_segmentation, mode='outer')\n",
        "    gt_boundaries = find_boundaries(ground_truth, mode='outer')\n",
        "\n",
        "    matched_boundary = np.logical_and(slic_boundaries, gt_boundaries)\n",
        "    recall = np.sum(matched_boundary) / np.sum(gt_boundaries)\n",
        "    return recall\n",
        "\n",
        "def undersegmentation_error(slic_segmentation, ground_truth):\n",
        "    ue = 0.0\n",
        "    slic_segmentation = slic_segmentation.astype(int)\n",
        "    ground_truth = ground_truth.astype(int)\n",
        "\n",
        "    for region in measure.regionprops(slic_segmentation):\n",
        "        gt_region = ground_truth[region.coords[:, 0], region.coords[:, 1]]\n",
        "        if len(gt_region) == 0:\n",
        "            continue\n",
        "        majority_label = np.bincount(gt_region).argmax()\n",
        "        leakage = np.sum(gt_region != majority_label)\n",
        "        ue += leakage / region.area\n",
        "    return ue / len(np.unique(slic_segmentation))\n",
        "\n",
        "br_list = []\n",
        "ue_list = []\n",
        "\n",
        "for file_name, ground_truth_segmentations in all_segmentations.items():\n",
        "    slic_segmentation = np.load(f' storage path for segmentations/SLIC_segmentation_{file_name}.npy')\n",
        "\n",
        "    ground_truth_segmentation = ground_truth_segmentations[0]\n",
        "\n",
        "    br = boundary_recall(slic_segmentation, ground_truth_segmentation)\n",
        "    ue = undersegmentation_error(slic_segmentation, ground_truth_segmentation)\n",
        "\n",
        "    br_list.append(br)\n",
        "    ue_list.append(ue)\n",
        "\n",
        "average_br = np.mean(br_list)\n",
        "average_ue = np.mean(ue_list)\n",
        "\n",
        "print(f\"Average Boundary Recall: {average_br}\")\n",
        "print(f\"Average Undersegmentation Error: {average_ue}\")\n"
      ],
      "metadata": {
        "id": "f4vsVfJWEVrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execute the main function"
      ],
      "metadata": {
        "id": "ZMl-nGn2CYSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "eInnWljvCKw4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}